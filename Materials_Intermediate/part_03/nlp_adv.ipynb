{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![embeddings.png](embeddings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@harsh.vardhan7695/a-comprehensive-guide-to-word-embeddings-in-nlp-ee3f9e4663ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transformer is a deep learning architecture that was developed by researchers at Google and is based on the multi-head attention mechanism, which was proposed in the 2017 paper \"Attention Is All You Need\".[1] https://arxiv.org/pdf/1706.03762"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  BERT (Bidirectional encoder representations from transformers)\n",
    "https://huggingface.co/docs/transformers/en/model_doc/bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://learn.epam.com/catalog/detailsPage?id=a19548e4-6f58-4eab-9105-2efc8daca64d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT base model (cased), This model is case-sensitive: it makes a difference between english and English.\n",
    "https://huggingface.co/google-bert/bert-base-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
